{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d9a84da-f4d8-46fe-8105-ff73e64551e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "import plotly.io as io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e1a59251-7723-494d-af2b-bcbc4c78015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cov/result_PVAL_71_S7.hist\", \n",
    "                 sep=\"\\t\", \n",
    "                 names=[\"chrom\", \"start\", \"end\", \"name\", \"score\", \"strand\",\"depth\",\"num_bases_at_depth\",\"size_of_feature\",\"pros_of_feature_at_depth\"])\n",
    "df = df[df.chrom != \"all\"].copy()\n",
    "df[['ID', 'rest']] = df['name'].str.split('_cds_', -1, expand=True) # https://stackoverflow.com/a/39358924\n",
    "df[[\"exon_number\", \"unknown\", \"exon_chrom\", \"exon_start_pos\", \"exon_strand\"]] = df['rest'].str.split('_', -1, expand=True)\n",
    "df = df.drop([\"name\",\"rest\"], axis = 1)\n",
    "\n",
    "df = df.astype({\n",
    "           'chrom':'str',\n",
    "           'start':'int',\n",
    "           'end':'int',\n",
    "           'score':'float',\n",
    "           'strand':'str',\n",
    "           'depth':'int',\n",
    "           'num_bases_at_depth':'int',\n",
    "           'size_of_feature':'int',\n",
    "           'pros_of_feature_at_depth':'float',\n",
    "           'ID':'category',\n",
    "           \"exon_number\":'category', \n",
    "           \"unknown\":'category', \n",
    "           \"exon_chrom\":\"category\", \n",
    "           \"exon_start_pos\":\"int\", \n",
    "           \"exon_strand\":\"category\"\n",
    "          }\n",
    "         )\n",
    "transcripts = df['ID'].unique()\n",
    "\n",
    "grouped = df.groupby(df.ID)\n",
    "\n",
    "transcripts_list = []\n",
    "\n",
    "for isof in transcripts:\n",
    "    c = grouped.get_group(isof)\n",
    "    # Scrape NCBI transcript ID\n",
    "    NCBI_id = c.iloc[0]['ID']\n",
    "    # Duplicate rows with several bases \n",
    "    c = c.loc[c.index.repeat(c.num_bases_at_depth)] # https://stackoverflow.com/a/57009491\n",
    "    # Extract key values for the depth column\n",
    "    c = c.describe()['depth'].to_frame(NCBI_id).T\n",
    "    transcripts_list.append(c)\n",
    "\n",
    "# Join all key data into one df\n",
    "all_transcripts = (pd.concat(transcripts_list, axis=0)\n",
    "                   .rename(columns={'count': 'total_exons_length'})\n",
    "                   .astype({\n",
    "                           'total_exons_length':'int',\n",
    "                           'max':'int',\n",
    "                           'min':'int'}\n",
    "                          )                  \n",
    "                  )\n",
    "all_transcripts.to_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de604d56-b06b-4ce6-a746-bed5b3c41e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_covs = Path('cov/')\n",
    "\n",
    "for path in sorted(sample_covs.glob(\"*.hist\")):\n",
    "    sample_name = str(path.stem).split(\"results_\")[1]\n",
    "    out_path = \"sample_coverages/\"\n",
    "    df = pd.read_csv(path, \n",
    "                     sep=\"\\t\", \n",
    "                     names=[\"chrom\", \"start\", \"end\", \"name\", \"score\", \"strand\",\"depth\",\"num_bases_at_depth\",\"size_of_feature\",\"pros_of_feature_at_depth\"])\n",
    "    df = df[df.chrom != \"all\"].copy()\n",
    "    df[['ID', 'rest']] = df['name'].str.split('_cds_', -1, expand=True) # https://stackoverflow.com/a/39358924\n",
    "    df[[\"exon_number\", \"unknown\", \"exon_chrom\", \"exon_start_pos\", \"exon_strand\"]] = df['rest'].str.split('_', -1, expand=True)\n",
    "    df = df.drop([\"name\",\"rest\"], axis = 1)\n",
    "\n",
    "    df = df.astype({\n",
    "               'chrom':'str',\n",
    "               'start':'int',\n",
    "               'end':'int',\n",
    "               'score':'float',\n",
    "               'strand':'str',\n",
    "               'depth':'int',\n",
    "               'num_bases_at_depth':'int',\n",
    "               'size_of_feature':'int',\n",
    "               'pros_of_feature_at_depth':'float',\n",
    "               'ID':'category',\n",
    "               \"exon_number\":'category', \n",
    "               \"unknown\":'category', \n",
    "               \"exon_chrom\":\"category\", \n",
    "               \"exon_start_pos\":\"int\", \n",
    "               \"exon_strand\":\"category\"\n",
    "              }\n",
    "             )\n",
    "    df = df.loc[df.index.repeat(df.num_bases_at_depth)] # https://stackoverflow.com/a/57009491\n",
    "    box_fig = px.box(df, x=\"ID\", y=\"depth\")\n",
    "    box_fig.write_html(out_path + \"box/\" + sample_name + \"_box\" + \".html\")    \n",
    "    #vio_fig = px.violin(df, x=\"ID\", y=\"depth\", box=True)\n",
    "    \n",
    "    # Extract a list of all unique NCBI ID:s\n",
    "    transcripts = df['ID'].unique()\n",
    "    \n",
    "    grouped = df.groupby(df.ID)\n",
    "\n",
    "    transcripts_list = []\n",
    "    \n",
    "    for isof in transcripts:\n",
    "        c = grouped.get_group(isof)\n",
    "        # Scrape NCBI transcript ID\n",
    "        NCBI_id = c.iloc[0]['ID']\n",
    "        # Duplicate rows with several bases \n",
    "        #c = c.loc[c.index.repeat(c.num_bases_at_depth)] # https://stackoverflow.com/a/57009491\n",
    "        # Extract key values for the depth column\n",
    "        c = c.describe()['depth'].to_frame(NCBI_id).T\n",
    "        transcripts_list.append(c)\n",
    "\n",
    "    # Join all key data into one df\n",
    "    all_transcripts = (pd.concat(transcripts_list, axis=0)\n",
    "                       .rename(columns={'count': 'total_exons_length'})\n",
    "                       .astype({\n",
    "                               'total_exons_length':'int',\n",
    "                               'max':'int',\n",
    "                               'min':'int'}\n",
    "                              )                  \n",
    "                      )\n",
    "    all_transcripts.index.name = \"NCBI_ID\"\n",
    "    bar_fig = px.bar(all_transcripts.reset_index(), x='NCBI_ID', y='mean')\n",
    "    bar_fig.write_html(out_path + \"bar/\" + sample_name + \"_bar\" + \".html\")\n",
    "    out_path = Path(out_path + \"metrics/\" + sample_name + \".csv\")\n",
    "    all_transcripts.to_csv(out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
